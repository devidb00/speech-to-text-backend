{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surah_names():\n",
    "    surah_names = [] #surah names sorted\n",
    "    URL = \"https://surahquran.com/quran-search/quran.html\"\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    all_table = soup.find_all('table')[1]\n",
    "    for idx, elm in enumerate(all_table.find_all(\"a\")):\n",
    "        surah_names.append(\n",
    "            (idx + 1, elm.text)\n",
    "        )\n",
    "    return surah_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = pd.read_csv(\n",
    "    f'{os.getcwd()}/data/french.csv',\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    ")\n",
    "book.columns = [\"sura\", \"ayat\", \"text\"]\n",
    "book['sura'] = book['sura'].astype(int)\n",
    "book['ayat'] = book['ayat'].astype(int)\n",
    "\n",
    "mapping_dictionary = {t[0]: t for t in get_surah_names()}\n",
    "book['sura_name'] = book['sura'].map(mapping_dictionary).apply(lambda t: t[1])\n",
    "\n",
    "def cleaning_text(text):\n",
    "    text = re.sub(r'` ', \"'\", text)\n",
    "    text = re.sub(r' +(\\.)', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "book[\"text\"] = book[\"text\"].apply(lambda x: cleaning_text(x))\n",
    "book['text'].to_csv(f'{os.getcwd()}/output.txt', index=False, sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "with open(f'{os.getcwd()}/output.txt') as file:\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "\n",
    "def find_sentences():\n",
    "    doc = nlp(text)\n",
    "    sentences = list(doc.sents)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "\n",
    "search_str = \"par un tel exemple\"\n",
    "book = book.assign(\n",
    "    score = lambda _df: \n",
    "        _df['text'].map(lambda t: \n",
    "            fuzz.partial_ratio(t, search_str)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book.sort_values('score', ascending=False)\n",
    "book.loc[32, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
